---
title: Academic Writing With AI
description: How I used AI to summarize complex text
date: "2023-09-08"
authors:
    - beneverman
---

## Introduction

The newest Large Language Models (LLMs) can do quite a bit out of the box. They can:
1. Generate text
2. Converse
3. Answer open book questions (you provide the context in the prompt)
4. Answer closed book questions (semi-accurately)

Fundamentally, LLMs are **deep neural networks trained on large datasets capable of generating natural language**. Stephen Wolfram wrote a great [technical intro](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/) to LLMs, though I'll be focusing on the application layer - how to use them (as opposed to building them).

## Writing Literature Reviews With AI

I had some grad school assignments where I had to write short (~1000 word) reviews of various literature. This led me to wonder if LLMs were capable of writing such a literature review. Turns out, they have some significant limitations - but they can be improved if used with **careful prompting, closed-book Q/A, data augmented retrieval, and Chain of Though (CoT) reasoning**.

## The Problems With LLMs and Academic Writing

### Hallucination

The first problem is that LLMs are generally pre-trained only once. They can be later adapted to a specific task with fine-tuning or reinforcement learning, though the underlying model architecture is still the same. The relevance here is that after the model is initially pre-trained on a dataset - it's computationally and logistically expensive to pre-train the same model on *new data*. For example, if a LLM is pre-trained on 1/1/2022, and I ask it, "Who won the Super Bowl in 2023?", it won't know. When it was pre-trained, the 2023 superbowl hadn't happened yet, so it couldn't have been included in the pre-training dataset. Furthermore, the model might hallucinate a believable answer, for example, "The New England Patriots won the Super Bowl in 2023." This is problematic, not only because it's inaccurate, but because it's actually plausible. In this situation - if you're a football fan - it's very clear that the answer is wrong, because you saw the Kansas City Chiefs beat the Philadelphia Eagles in the 2023 Super Bowl. If you're not a football fan, you'll think, *Oh yeah, I know the Patriots. They're usually pretty good, aren't they?*, then move on.

My point here is this: **when LLMs hallucinate, they will do so convincingly enough that you're at serious risk of believing it**. We're mostly accustomed to search engines, which are fundamentally different. In the case of an an academic literature review, it's clear how this could be problematic.

### Inaccurate Citations

The second problem is that LLMs are generally considered **black-box** technology - the inner workings are not easily observed or interpreted. Since LLMs are often stochastic (inherently random and probabilistic) in training and can be non-deterministic (variable or uncertain) during inference, if I ask a LLM a question, it's unknown what data it's using to answer that question. This is explored further in a sub-field called [Explainable AI](https://cloud.google.com/explainable-ai#:~:text=Explainable%20AI%20is%20a%20set,others%20understand%20your%20models'%20behavior.) or XAI. The significance here is that the model can't cite its sources - which is paramount in academia.

### Inability to Meaningfully Reason or Cognate

The third problem is that LLMs are unable to cognate. But what constitutes cognition, anyway?

Artificial Intelligence is designed to emulate human-like "understanding" by modeling complex latent relationships between variables. LLMs feel particularly compelling because they do this with natural language (via tokens). As I mentioned earlier, we tend to be used to retrieval as opposed to generation, so when a LLM performs accurately on an out-of-sample test (something it has never seen), it feels like the model is actually *thinking* like a human would, more than just memorizing (or indexing) and regurgitating like a search engine would. And it is - kind of. There are differing perspectives on the relationship between AI and human cognition.

The biggest practical breakthrough in LLM "cognition" has been that, **with specific prompts, we can facilitate reasoning and improve model performance on tasks that require cognition**. Yao et al. published a paper in 2022 entitled, [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629) in which they demonstrated a method for improving LLM performance on tasks that require reasoning known as the ReAct method (or Reason + Act). Later, in 2023, Yang et al. published a paper entitled [Large Language Models as Optimizers](https://arxiv.org/pdf/2309.03409.pdf) where they showed how certain instructions facilitated better performance on reasoning based tasks. All this is fairly intuitive, and the key takeaway is that **LLMs can be prompted to perform better on tasks that require reasoning**.

## My Solution

The original task was writing a short literature review, while attempting to circumvent or mitigate the problems mentioned above. My methodology for building a python script to do this was as follows:

1. Always provide context in the prompt to mitigate the black-box problem
2. Ask closed book questions to mitigate the hallucination problem
3. Prompt the model to respond "X was not provided in the context", if it lacks information 
4. Facilitate reasoning by modeling my typical chain of thought

### The Chain
Check out the code [here](https://github.com/beverm2391/ai-summarizer-v2).

1. Take a journal and split it into chunks
2. Operate on each chunk with a specific prompt, concurrently
    1. List the main ideas
    2. Identify 2-3 direct quotes
    3. Identify potential weaknesses, strengths, of the author's argument
    4. Optional - specific synthesis question(s)
3. Take groups of model responses and aggregate them with a different prompt
    1. Combine the material to create content
    2. Optional - add additional instructions, do some sort of analysis, etc.
4. Recursively combine sections until the input can be passed in a single prompt
    1. Aggregate the content into a coherent paper with appropriate heading/subheadings
    2. Optional - add an introduction and conclusion

The appropriate citation is generated from the metadata in the PDF, then passed through each prompt along with a separate instruction on maintaining citations.

Here's an example output from a single article.

<Callout> Original Article: [An Examination of Automatic Tomato Detection with an Improved YOLOv8s Model](https://www.mdpi.com/2073-4395/13/7/1824) </Callout>

<Card className='mt-4 text-sm sm:text-base [&:p]:mt-4'>
# Article Summary: Computer Vision and Agriculture

The rapid advancement of technology has opened up new paths in the realm of agriculture, leading to increased levels of automation in various farming activities. One such development is the use of automatic detection algorithms for identifying and picking tomatoes, a crucial step in tomato harvesting. This essay delves into the innovative work of Yang et al. (2023) in this area, who have proposed a lightweight YOLOv8 Tomato Detection Algorithm that combines feature enhancement and attention to enhance the efficiency of tomato harvesting.

## A Three-Component Solution

Yang et al.'s (2023) method addresses the low level of automation in tomato harvesting by incorporating three key components into an improved YOLOv8s model: the depthwise separable convolution (DSConv), the dual-path attention gate module (DPAG), and the feature enhancement module (FEM).

The DSConv technique replaces the ordinary convolution, significantly reducing the computational complexity by generating numerous feature maps with minimal calculation. This not only reduces the computational burden but also improves the efficiency of the algorithm (Yang et al., 2023).

The DPAG module is designed to enhance the model's detection precision in complex environments. It does this by improving the networkâ€™s ability to distinguish between tomatoes and the background, thereby improving the model's detection capability in complex environments (Yang et al., 2023).

Lastly, the FEM module is introduced to highlight target details and prevent the loss of effective features. This enhances the detection precision by ensuring that the important aspects of each image are effectively captured and analyzed (Yang et al., 2023).

## Performance Evaluation

The performance of Yang et al.'s (2023) proposed algorithm was evaluated against other well-established algorithms such as SSD, faster R-CNN, YOLOv4, YOLOv5, and YOLOv7. The evaluation metrics used included precision, recall rate, and mean average precision (mAP).

The results of this comparative analysis demonstrated the superiority of the improved YOLOv8s network. The network exhibited a lower loss and 93.4% mAP on the tomato dataset, a 1.5% increase compared to the model before improvement. Furthermore, the precision increased by 2%, and the recall rate increased by 0.8% (Yang et al., 2023).

Notably, the proposed algorithm significantly reduced the model size from 22 M to 16 M, while achieving a detection speed of 138.8 FPS, which meets the real-time detection requirement. This balance between model size and detection precision makes it highly suitable for the demands of agricultural tomato detection (Yang et al., 2023).

## Conclusion and Future Implications

Yang et al.'s (2023) innovative method offers a promising approach to improving the automation level in tomato harvesting. The improved YOLOv8s model not only enhances detection precision but also maintains a small model size and high detection speed, thereby meeting the requirements of agricultural tomato detection.

The practical implication of this development is that it can provide technical support for a tomato picking robot, ensuring its fast and accurate operation. This advancement can significantly optimize the tomato harvesting process, leading to increased productivity and efficiency in agricultural production activities.

There is no doubt that the research by Yang et al. (2023) marks a significant step forward in the field of agricultural automation. As technology continues to evolve, it is expected that such methods will become even more refined and effective, leading to even greater levels of automation and efficiency in agriculture.

## References

Yang, G., Wang, J., Nie, Z., Yang, H., & Yu, S. (2023). A Lightweight YOLOv8 Tomato Detection Algorithm Combining Feature Enhancement and Attention. pdfTeX-1.40.21.

</Card>

If you're used to working with LLMs, you'll notice that on the surface, this output is close to what you'd get out of the box. On further inspection, you'll notice that its factual, appropriately cited, and well reasoned.

### Implications for My Writing

At one point I was toying with the idea of automating a bigger review. To me, the idea of typing in a search topic, running a Python script, and trying to submit the fully-automated output to a journal seems like a fun challenge. 

If that were my goal, I'd probably do something like this:
1. Run a search on PubMed/ArXiv/JAMA/etc. for a specific topic
2. Download the PDFs and embed them into vectors
3. Generate a semantic schema of the ideas present in the literature
    1. Run K-means clustering on the vectors
    2. Run a topic model on the vectors
    3. Generate a JSON schema of the literature with relevant content and citations nested under each topic
4. Recursively iterate over the schema, generating content for the review
5. Aggregate the content into a coherent paper with appropriate heading/subheadings
6. Add an introduction and conclusion

Something else I experimented with was getting an LLM to output in my own style of writing. I imagine that if I were to fine-tune an open source model like [Llama 2](https://ai.meta.com/llama/) on a corpus of my writing, I could get a pretty decent output. I think the main problem here would be collecting enough source material.

Ultimately though, I think the best use of LLMs is to augment my writing, not automate it. I find myself most often using LLMs to rephrase/reword things, cultivate my scattered thoughts into coherent sentences, and to make my writing more concise. This is probably how I'll continue to use LLMs in the future. No neural network is going to replace my brain (the ultimate neural network)... for now.

<Callout> Thanks for making it this far! You can see the code [here](https://github.com/beverm2391/ai-summarizer-v2). Feel free to reach out on [Twitter (X)](https://twitter.com/beneverman) or via [email](mailto:evermanben@gmail.com).</Callout>