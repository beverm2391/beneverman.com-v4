---
title: Academic Writing With AI
description: How I used AI to summarize complex text
date: "2023-09-08"
authors:
    - beneverman
---

## Introduction

The newest Large Language Models (LLMs) can do quite a bit out of the box. They can:
1. Generate text
2. Converse
3. Answer open book questions (you provide the context in the prompt)
4. Answer closed book questions (semi-accurately)

Fundamentally, they are **deep neural networks trained on large datasets capable of generating natural language**. Stephen Wolfram wrote a great [technical intro](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/) to LLMs, though I'll be focusing on the application layer - how to use them (as opposed to building them).

## Writing Literature Reviews With AI

I had some grad school assignments where I had to write short (~1000 word) reviews of various literature. This led me to wonder if LLMs were capable of writing such a literature review. Turns out, they have some significant limitations - but they can be improved if used with **careful prompting, closed-book Q/A, data augmented retrieval, and Chain of Though (CoT) reasoning**. In this case, I was able to select a PDF article of interest, run a custom Python script, and get the following 500 word review in about 3 minutes.

<Callout> Original Article: [An Examination of Automatic Tomato Detection with an Improved YOLOv8s Model](https://www.mdpi.com/2073-4395/13/7/1824) </Callout>

<Card className='mt-4 text-sm sm:text-base'>
# An Examination of Automatic Tomato Detection with an Improved YOLOv8s Model

The rapid advancement of technology has opened up new paths in the realm of agriculture, leading to increased levels of automation in various farming activities. One such development is the use of automatic detection algorithms for identifying and picking tomatoes, a crucial step in tomato harvesting. This essay delves into the innovative work of Yang et al. (2023) in this area, who have proposed a lightweight YOLOv8 Tomato Detection Algorithm that combines feature enhancement and attention to enhance the efficiency of tomato harvesting.

## A Three-Component Solution

Yang et al.'s (2023) method addresses the low level of automation in tomato harvesting by incorporating three key components into an improved YOLOv8s model: the depthwise separable convolution (DSConv), the dual-path attention gate module (DPAG), and the feature enhancement module (FEM).

The DSConv technique replaces the ordinary convolution, significantly reducing the computational complexity by generating numerous feature maps with minimal calculation. This not only reduces the computational burden but also improves the efficiency of the algorithm (Yang et al., 2023).

The DPAG module is designed to enhance the model's detection precision in complex environments. It does this by improving the networkâ€™s ability to distinguish between tomatoes and the background, thereby improving the model's detection capability in complex environments (Yang et al., 2023).

Lastly, the FEM module is introduced to highlight target details and prevent the loss of effective features. This enhances the detection precision by ensuring that the important aspects of each image are effectively captured and analyzed (Yang et al., 2023).

## Performance Evaluation

The performance of Yang et al.'s (2023) proposed algorithm was evaluated against other well-established algorithms such as SSD, faster R-CNN, YOLOv4, YOLOv5, and YOLOv7. The evaluation metrics used included precision, recall rate, and mean average precision (mAP).

The results of this comparative analysis demonstrated the superiority of the improved YOLOv8s network. The network exhibited a lower loss and 93.4% mAP on the tomato dataset, a 1.5% increase compared to the model before improvement. Furthermore, the precision increased by 2%, and the recall rate increased by 0.8% (Yang et al., 2023).

Notably, the proposed algorithm significantly reduced the model size from 22 M to 16 M, while achieving a detection speed of 138.8 FPS, which meets the real-time detection requirement. This balance between model size and detection precision makes it highly suitable for the demands of agricultural tomato detection (Yang et al., 2023).

## Conclusion and Future Implications

Yang et al.'s (2023) innovative method offers a promising approach to improving the automation level in tomato harvesting. The improved YOLOv8s model not only enhances detection precision but also maintains a small model size and high detection speed, thereby meeting the requirements of agricultural tomato detection.

The practical implication of this development is that it can provide technical support for a tomato picking robot, ensuring its fast and accurate operation. This advancement can significantly optimize the tomato harvesting process, leading to increased productivity and efficiency in agricultural production activities.

There is no doubt that the research by Yang et al. (2023) marks a significant step forward in the field of agricultural automation. As technology continues to evolve, it is expected that such methods will become even more refined and effective, leading to even greater levels of automation and efficiency in agriculture.

## References

Yang, G., Wang, J., Nie, Z., Yang, H., & Yu, S. (2023). A Lightweight YOLOv8 Tomato Detection Algorithm Combining Feature Enhancement and Attention. pdfTeX-1.40.21.

</Card>

It may not look that impressive, but it shouldn't at first glance. We're used to LLMs generating academic-esq responses out of the box. But that's the key - the problem isn't getting an *academic sounding response*, it's getting an *academically accurate response*. And it's not enough to have 99% accuracy, because academic literature must be fully factual, appropriately cited, and well reasoned.

## The Problems With LLMs and Academic Writing

### Hallucination

The first problem is that LLMs are generally pre-trained only once. They can be later adapted to a specific task with fine-tuning or reinforcement learning, though the underlying model architecture is still the same. The relevance here is that after the model is initially pre-trained on a dataset - it's computationally and logistically expensive to pre-train the same model on *new data*. For example, if a LLM is pre-trained on 1/1/2022, and I ask it, "Who won the Super Bowl in 2023?", it won't know. The 2023 superbowl hasn't happened yet, so it couldn't have been included in the pre-training dataset. Furthermore, the model might hallucinate a believable answer, for example, "The New England Patriots won the Super Bowl in 2023." This is problematic, not only because it's inaccurate, but because it's actually plausible. In this situation - if you're a football fan - it's very clear that the answer is wrong, because you saw the Kansas City Chiefs beat the Philadelphia Eagles in the 2023 Super Bowl. If you're not a football fan, you'll think, *Oh yeah, I know the Patriots. They're usually pretty good, aren't they?* Then you'll move on.

My point here is this: **when LLMs hallucinate, they will do so convincingly enough that you're at serious risk of believing it**. We're mostly accustomed to search engines, which are fundamentally different. In the case of an an academic literature review, it's clear how this could be problematic.

### Inaccurate Citations

The second problem is that LLMs are generally considered **black-box** technology - the inner workings are not easily observed or interpreted. LLMs are often stochastic (inherently random and probabilistic) in training and can be non-deterministic (variable or uncertain) during inference. This is explored in a sub-field called [Explainable AI](https://cloud.google.com/explainable-ai#:~:text=Explainable%20AI%20is%20a%20set,others%20understand%20your%20models'%20behavior.) or XAI.


### Inability to Meaningfully Reason or Cognate

The third problem 

Artificial Intelligence is designed to emulate human-like "understanding" by modeling complex latent variables. LLMs feel particularly compelling because they do this with natural language. As I mentioned earlier, we tend to be used to memorization, so when a LLM performs accurately on an out-of-sample test (something it has never seen), it feels like the model is actually *thinking* like a human would, more than just memorizing and regurgitating like a search engine would. And it is - kind of. There are differing perspectives on the relationship between AI and human cognition. For this purpose, it's more pragmatical to focus on the model's ability to perform on a discrete, quasi-measurable benchmark. In this case, the benchmark is the ability to write a factually accurate, appropriately cited, and well reasoned academic literature review.